{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "colab": {
      "name": "homework4.ipynb",
      "provenance": [],
      "include_colab_link": true
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/yeb2Binfang/DS_GY_3001_CV/blob/main/HW/HW4/homework4.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lxSbbsu-ILwt"
      },
      "source": [
        "## Homework 4: Neural Networks"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dAsZafSmILw0"
      },
      "source": [
        "**Due date:** May 2, 2021\n",
        "\n",
        "The goal of the assignment is to train a simple neural network on MNIST data.\n",
        "\n",
        "*Note:* This notebook requires Python 3.\n",
        "\n",
        "**Instructions:**\n",
        "\n",
        "* Read and understand the provided code, which is a basic implementation of a neural network as a modular architecture.\n",
        "* Download the [MNIST data](http://deeplearning.net/data/mnist/mnist.pkl.gz) (~15Mo). It consists of 28x28 images (loaded as a 784 vector) and the associated labels for training, validation and test sets. For this homework, you will only use the training and validation sets. \n",
        "* Write a simple loop to train 50 iterations of the implemented MLP (multi-layer perceptron) with a learning rate 0.001 and batches of size 16. Plot the training and validation losses throughout the training process (you don't have to test your network at every iteration, you can do it for example every 10 iterations).\n",
        "* Evaluate the accuracy of your trained model on the training and validation data. Check the predictions on random validation images.\n",
        "* Try changing learning rate and batch size and see if you can improve your results.\n",
        "* How many parameters does the network have? Implement and experiment with some variations of the architecture, for example:\n",
        "    * Implement and use the cross-entropy loss instead of L2 loss.\n",
        "    * Add a parameter to vary the size of the intermediate layer.\n",
        "    * Use a MLP with 3 layers and parameters for the sizes of the two intermediate layers.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dUU83TWnILw1"
      },
      "source": [
        "## MLP implementation"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JpDfwN0CqSMh"
      },
      "source": [
        "### Import packages"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XgIaJtE1ITo_"
      },
      "source": [
        "import numpy as np \n",
        "import math\n",
        "import matplotlib.pyplot as plt \n",
        "%matplotlib inline \n",
        "plt.rcParams['image.cmap'] = 'gray' \n",
        "import gzip\n",
        "import pickle"
      ],
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7ycydqOgqXNb"
      },
      "source": [
        "### Module"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BveJTLEqqblb"
      },
      "source": [
        "class Module(object):\n",
        "    def __init__(self):\n",
        "        self.gradInput=None \n",
        "        self.output=None\n",
        "        \n",
        "    def forward(self, *input):\n",
        "        \"\"\"Defines the computation performed at every call.\n",
        "        Should be overriden by all subclasses.\n",
        "        \"\"\"\n",
        "        raise NotImplementedError\n",
        "        \n",
        "    def backward(self, *input):\n",
        "        \"\"\"Defines the computation performed at every call.\n",
        "        Should be overriden by all subclasses.\n",
        "        \"\"\"\n",
        "        raise NotImplementedError"
      ],
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1D4c68eHqkHV"
      },
      "source": [
        "### Linear"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "n2XzZLxwqpfJ"
      },
      "source": [
        "class Linear(Module):\n",
        "    \"\"\"\n",
        "    The input is supposed to have two dimensions (batchSize,in_feature)\n",
        "    \"\"\"\n",
        "    def __init__(self, in_features, out_features, bias=True):\n",
        "        super(Linear, self).__init__()\n",
        "        self.in_features = in_features\n",
        "        self.out_features = out_features\n",
        "        self.weight = math.sqrt(1. / (out_features* in_features))*np.random.randn(out_features, in_features)\n",
        "        self.bias = np.zeros(out_features)\n",
        "        self.gradWeight=None\n",
        "        self.gradBias=None\n",
        "        \n",
        "    def forward(self, x):\n",
        "        self.output= np.dot(x,self.weight.transpose())+np.repeat(self.bias.reshape([1,-1]),x.shape[0], axis=0)\n",
        "        return self.output\n",
        "    \n",
        "    def backward(self, x, gradOutput):\n",
        "        self.gradInput=np.dot(gradOutput,self.weight)\n",
        "        self.gradWeight=np.dot(gradOutput.transpose(),x)\n",
        "        self.gradBias=np.sum(gradOutput, axis=0)\n",
        "        return self.gradInput\n",
        "    \n",
        "    def gradientStep(self,lr):\n",
        "        self.weight=self.weight-lr*self.gradWeight\n",
        "        self.bias=self.bias-lr*self.gradBias"
      ],
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_JDwCvzuqx8k"
      },
      "source": [
        "### ReLU"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jz6hOk57q0xE"
      },
      "source": [
        "class ReLU(Module):\n",
        "    \n",
        "    def __init__(self, bias=True):\n",
        "        super(ReLU, self).__init__()\n",
        "        \n",
        "    def forward(self, x):\n",
        "        self.output=x.clip(0)\n",
        "        return self.output\n",
        "    \n",
        "    def backward(self, x, gradOutput):\n",
        "        self.gradInput=(x>0)*gradOutput\n",
        "        return self.gradInput"
      ],
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7u3dBSEEqrHW"
      },
      "source": [
        "### Least Square Error\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Z8US9iumqvIK"
      },
      "source": [
        "class LeastSquareCriterion(Module):\n",
        "    \"\"\"\n",
        "    This implementation of the least square loss assumes that the data comes as a 2 dimensional array\n",
        "    of size (batch_size,num_classes) and the labels as a vector of size (num_classes) \n",
        "    \"\"\"\n",
        "    def __init__(self, num_classes=10):\n",
        "        super(LeastSquareCriterion, self).__init__()\n",
        "        self.num_classes=num_classes\n",
        "    \n",
        "    def forward(self, x,labels):\n",
        "        target=np.zeros([x.shape[0],self.num_classes])\n",
        "        for i in range(x.shape[0]):\n",
        "            target[i,labels[i]]=1\n",
        "        self.output = np.sum((target-x)**2,axis=0)\n",
        "        return np.sum(self.output)\n",
        "    \n",
        "    def backward(self, x, labels):\n",
        "        self.gradInput=x\n",
        "        for i in range(x.shape[0]):\n",
        "            self.gradInput[i,labels[i]]=x[i,labels[i]]-1\n",
        "        return self.gradInput"
      ],
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ojBZ-MX5q4Yh"
      },
      "source": [
        "### MLP "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WiUZmgibILw1"
      },
      "source": [
        "class MLP(Module):\n",
        "\n",
        "    def __init__(self, num_classes=10):\n",
        "        super(MLP, self).__init__()\n",
        "        self.fc1 = Linear(784, 64)\n",
        "        self.relu1 = ReLU()\n",
        "        self.fc2 = Linear(64, 10)\n",
        "    \n",
        "    def forward(self, x):\n",
        "        x = self.fc1.forward(x)\n",
        "        x = self.relu1.forward(x)\n",
        "        x = self.fc2.forward(x)\n",
        "        return x\n",
        "    \n",
        "    def backward(self, x, gradient):\n",
        "        gradient = self.fc2.backward(self.relu1.output,gradient)\n",
        "        gradient = self.relu1.backward(self.fc1.output,gradient)\n",
        "        gradient = self.fc1.backward(x,gradient)\n",
        "        return gradient\n",
        "    \n",
        "    def gradientStep(self,lr):\n",
        "        self.fc2.gradientStep(lr)\n",
        "        self.fc1.gradientStep(lr)\n",
        "        return True"
      ],
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rFZeLd-3ILw3"
      },
      "source": [
        "## Load and visualize the dataset"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pRR08ypYKeEa",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a1b57c65-9115-461a-f69a-2794cdd164f7"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/MyDrive')"
      ],
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Mounted at /content/MyDrive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "X4t_TkeHKIT2"
      },
      "source": [
        "with open('MyDrive/MyDrive/DS/mnist.pkl', 'rb') as f:\n",
        "  ((x_train, y_train), (x_valid, y_valid), (x_test, y_test)) = pickle.load(f, encoding='latin-1')"
      ],
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WdC-TGrpKr_7",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 282
        },
        "outputId": "638d5df2-51c0-45c9-af62-aeec23a59026"
      },
      "source": [
        "plt.imshow(x_train[0].reshape((28,28)))"
      ],
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<matplotlib.image.AxesImage at 0x7f080777f650>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 18
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cWAjCprcLCH0",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "748f02da-3a7e-4a81-ff16-3076cc053596"
      },
      "source": [
        "print(y_train[0])"
      ],
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "5\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sRKL6R0trDV-"
      },
      "source": [
        "## Train MLP\n",
        "Write a simple loop to train 50 iterations of the implemented MLP (multi-layer perceptron) with a learning rate 0.001 and batches of size 16. Plot the training and validation losses throughout the training process (you don't have to test your network at every iteration, you can do it for example every 10 iterations)."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "80Z_B0Q0AFWS",
        "outputId": "549a6bdf-763f-40a4-ac03-8734d022fba1",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "pip install tqdm"
      ],
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.7/dist-packages (4.41.1)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7QOA4vySAJle"
      },
      "source": [
        "from tqdm import tqdm"
      ],
      "execution_count": 24,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ckXlHD58rJAG",
        "outputId": "bb3c87f3-52ec-401b-a3e0-baab01377efa",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "Net = MLP()\n",
        "Error = LeastSquareCriterion()\n",
        "\n",
        "n_iter = 50\n",
        "lr = 0.001\n",
        "batch_size = 16\n",
        "\n",
        "train_errors = []\n",
        "val_errors = []\n",
        "for epoch in range(n_iter):\n",
        "  #print(str(epoch) + \" epoch\")\n",
        "  if (epoch%10 == 0):\n",
        "    #write your code here\n",
        "    val_forward = Net.forward(x_valid)\n",
        "    val_loss = Error.forward(val_forward, y_valid)\n",
        "    val_errors.append(val_loss)\n",
        "\n",
        "    train_forward = Net.forward(x_train)\n",
        "    train_loss = Error.forward(train_forward, y_train)\n",
        "    train_errors.append(train_loss)\n",
        "\n",
        "  for i in tqdm(range(0,len(x_train),batch_size)):\n",
        "    #write your code here\n",
        "    if i==0:\n",
        "      continue\n",
        "    index = np.arange(i-batch_size,i)\n",
        "    x_forward = Net.forward(x_train[index])\n",
        "    grad_loss = Error.backward(x_forward, y_train[index])\n",
        "    Net.backward(x_train[index], grad_loss)\n",
        "    Net.gradientStep(lr)\n"
      ],
      "execution_count": 37,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "100%|██████████| 3125/3125 [00:04<00:00, 738.20it/s]\n",
            "100%|██████████| 3125/3125 [00:04<00:00, 768.47it/s]\n",
            "100%|██████████| 3125/3125 [00:04<00:00, 760.14it/s]\n",
            "100%|██████████| 3125/3125 [00:04<00:00, 747.13it/s]\n",
            "100%|██████████| 3125/3125 [00:04<00:00, 736.56it/s]\n",
            "100%|██████████| 3125/3125 [00:04<00:00, 737.04it/s]\n",
            "100%|██████████| 3125/3125 [00:04<00:00, 743.66it/s]\n",
            "100%|██████████| 3125/3125 [00:04<00:00, 733.64it/s]\n",
            "100%|██████████| 3125/3125 [00:04<00:00, 762.21it/s]\n",
            "100%|██████████| 3125/3125 [00:04<00:00, 750.33it/s]\n",
            "100%|██████████| 3125/3125 [00:04<00:00, 654.46it/s]\n",
            "100%|██████████| 3125/3125 [00:04<00:00, 647.93it/s]\n",
            "100%|██████████| 3125/3125 [00:04<00:00, 672.82it/s]\n",
            "100%|██████████| 3125/3125 [00:04<00:00, 674.45it/s]\n",
            "100%|██████████| 3125/3125 [00:04<00:00, 670.77it/s]\n",
            "100%|██████████| 3125/3125 [00:04<00:00, 665.16it/s]\n",
            "100%|██████████| 3125/3125 [00:04<00:00, 662.44it/s]\n",
            "100%|██████████| 3125/3125 [00:04<00:00, 665.24it/s]\n",
            "100%|██████████| 3125/3125 [00:04<00:00, 646.32it/s]\n",
            "100%|██████████| 3125/3125 [00:04<00:00, 682.43it/s]\n",
            "100%|██████████| 3125/3125 [00:04<00:00, 755.06it/s]\n",
            "100%|██████████| 3125/3125 [00:04<00:00, 773.38it/s]\n",
            "100%|██████████| 3125/3125 [00:04<00:00, 742.09it/s]\n",
            "100%|██████████| 3125/3125 [00:04<00:00, 747.65it/s]\n",
            "100%|██████████| 3125/3125 [00:04<00:00, 761.60it/s]\n",
            "100%|██████████| 3125/3125 [00:04<00:00, 751.39it/s]\n",
            "100%|██████████| 3125/3125 [00:04<00:00, 757.52it/s]\n",
            "100%|██████████| 3125/3125 [00:04<00:00, 748.67it/s]\n",
            "100%|██████████| 3125/3125 [00:04<00:00, 762.61it/s]\n",
            "100%|██████████| 3125/3125 [00:04<00:00, 750.86it/s]\n",
            "100%|██████████| 3125/3125 [00:04<00:00, 752.95it/s]\n",
            "100%|██████████| 3125/3125 [00:04<00:00, 751.26it/s]\n",
            "100%|██████████| 3125/3125 [00:04<00:00, 760.36it/s]\n",
            "100%|██████████| 3125/3125 [00:04<00:00, 779.21it/s]\n",
            "100%|██████████| 3125/3125 [00:04<00:00, 771.22it/s]\n",
            "100%|██████████| 3125/3125 [00:04<00:00, 776.70it/s]\n",
            "100%|██████████| 3125/3125 [00:04<00:00, 767.75it/s]\n",
            "100%|██████████| 3125/3125 [00:03<00:00, 781.37it/s]\n",
            "100%|██████████| 3125/3125 [00:04<00:00, 766.81it/s]\n",
            "100%|██████████| 3125/3125 [00:04<00:00, 774.36it/s]\n",
            "100%|██████████| 3125/3125 [00:04<00:00, 735.40it/s]\n",
            "100%|██████████| 3125/3125 [00:04<00:00, 742.74it/s]\n",
            "100%|██████████| 3125/3125 [00:04<00:00, 743.23it/s]\n",
            "100%|██████████| 3125/3125 [00:04<00:00, 740.90it/s]\n",
            "100%|██████████| 3125/3125 [00:04<00:00, 725.72it/s]\n",
            "100%|██████████| 3125/3125 [00:04<00:00, 745.43it/s]\n",
            "100%|██████████| 3125/3125 [00:04<00:00, 730.01it/s]\n",
            "100%|██████████| 3125/3125 [00:04<00:00, 736.51it/s]\n",
            "100%|██████████| 3125/3125 [00:04<00:00, 721.22it/s]\n",
            "100%|██████████| 3125/3125 [00:04<00:00, 729.31it/s]\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pFPF55nTCfH1",
        "outputId": "52b184fe-deee-4689-e1f4-2670547e8bd8",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "print(train_errors)"
      ],
      "execution_count": 38,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[49849.86147166136, 5907.882384508182, 4891.491765174849, 4447.502279344168, 4214.750902104069]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VbP4c0SfCSz7",
        "outputId": "9be1ac5d-f87b-4343-8e50-e51eaee36e53",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 282
        }
      },
      "source": [
        "train_loss = np.array(train_errors)/len(x_train)\n",
        "val_loss = np.array(val_errors)/len(x_valid)\n",
        "plt.plot(train_loss)\n",
        "plt.plot(val_loss)\n",
        "plt.legend([\"train_error\",\"val_error\"])"
      ],
      "execution_count": 52,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<matplotlib.legend.Legend at 0x7f07fd0d00d0>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 52
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OeZgY7AUrR20"
      },
      "source": [
        "## Evaluate the model accuracy\n",
        "Evaluate the accuracy of your trained model on the training and validation data. Check the predictions on random validation images."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "a3TXUFzsrcFr",
        "outputId": "d59e4360-d286-4c7f-b8db-753b8769226a",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "val_predictions = Net.forward(x_valid)\n",
        "train_predictions = Net.forward(x_train)\n",
        "\n",
        "print(\"Average train error:\")\n",
        "print(Error.forward(train_predictions,y_train)/len(x_train))\n",
        "\n",
        "print(\"Average validation error:\")\n",
        "print(Error.forward(val_predictions,y_valid)/len(x_valid))"
      ],
      "execution_count": 44,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Average train error:\n",
            "0.08093237785963325\n",
            "Average validation error:\n",
            "0.09322046514861149\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-gRPG_X13it0",
        "outputId": "6484fb1d-babf-4833-d4bf-0997ca5547b6",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 298
        }
      },
      "source": [
        "m = np.random.randint(len(x_valid))\n",
        "plt.imshow(x_valid[m,:].reshape(28,28))\n",
        "print(\"true label: \"+str(y_valid[m]))\n",
        "prediction = Net.forward(x_valid[m,:].reshape([1,-1]))\n",
        "print(\"predict label: \"+ str(prediction.argmax()))"
      ],
      "execution_count": 48,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "true label: 1\n",
            "predict label: 1\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PUUaJIo1rcgX"
      },
      "source": [
        "## Try to imporve\n",
        "Try changing learning rate and batch size and see if you can improve your results.\n",
        "Here, I changed learning rate to 0.0001 and changed the batch-size to 8. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xAAclVGBrhyl",
        "outputId": "9d338b23-25f9-477a-e1b7-f2965fa44072",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "Net1 = MLP()\n",
        "Error1 = LeastSquareCriterion()\n",
        "\n",
        "n_iter = 50\n",
        "lr1 = 0.0001\n",
        "batch_size1 = 8\n",
        "\n",
        "train_errors1 = []\n",
        "val_errors1 = []\n",
        "for epoch in range(n_iter):\n",
        "  #print(str(epoch) + \" epoch\")\n",
        "  if (epoch%10 == 0):\n",
        "    #write your code here\n",
        "    val_forward = Net1.forward(x_valid)\n",
        "    val_loss = Error1.forward(val_forward, y_valid)\n",
        "    val_errors1.append(val_loss)\n",
        "\n",
        "    train_forward = Net1.forward(x_train)\n",
        "    train_loss = Error1.forward(train_forward, y_train)\n",
        "    train_errors1.append(train_loss)\n",
        "\n",
        "  for i in tqdm(range(0,len(x_train),batch_size1)):\n",
        "    #write your code here\n",
        "    if i==0:\n",
        "      continue\n",
        "    index = np.arange(i-batch_size1,i)\n",
        "    x_forward = Net1.forward(x_train[index])\n",
        "    grad_loss = Error1.backward(x_forward, y_train[index])\n",
        "    Net1.backward(x_train[index], grad_loss)\n",
        "    Net1.gradientStep(lr1)"
      ],
      "execution_count": 56,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "100%|██████████| 6250/6250 [00:06<00:00, 930.01it/s]\n",
            "100%|██████████| 6250/6250 [00:06<00:00, 932.08it/s]\n",
            "100%|██████████| 6250/6250 [00:06<00:00, 917.65it/s]\n",
            "100%|██████████| 6250/6250 [00:06<00:00, 939.55it/s]\n",
            "100%|██████████| 6250/6250 [00:06<00:00, 914.24it/s]\n",
            "100%|██████████| 6250/6250 [00:06<00:00, 912.30it/s]\n",
            "100%|██████████| 6250/6250 [00:06<00:00, 911.58it/s]\n",
            "100%|██████████| 6250/6250 [00:06<00:00, 928.68it/s]\n",
            "100%|██████████| 6250/6250 [00:06<00:00, 921.22it/s]\n",
            "100%|██████████| 6250/6250 [00:06<00:00, 923.18it/s]\n",
            "100%|██████████| 6250/6250 [00:06<00:00, 926.65it/s]\n",
            "100%|██████████| 6250/6250 [00:06<00:00, 920.43it/s]\n",
            "100%|██████████| 6250/6250 [00:06<00:00, 918.54it/s]\n",
            "100%|██████████| 6250/6250 [00:06<00:00, 926.88it/s]\n",
            "100%|██████████| 6250/6250 [00:06<00:00, 898.01it/s]\n",
            "100%|██████████| 6250/6250 [00:06<00:00, 919.93it/s]\n",
            "100%|██████████| 6250/6250 [00:06<00:00, 912.09it/s]\n",
            "100%|██████████| 6250/6250 [00:06<00:00, 925.70it/s]\n",
            "100%|██████████| 6250/6250 [00:06<00:00, 915.53it/s]\n",
            "100%|██████████| 6250/6250 [00:06<00:00, 905.68it/s]\n",
            "100%|██████████| 6250/6250 [00:07<00:00, 888.79it/s]\n",
            "100%|██████████| 6250/6250 [00:07<00:00, 890.02it/s]\n",
            "100%|██████████| 6250/6250 [00:07<00:00, 884.19it/s]\n",
            "100%|██████████| 6250/6250 [00:06<00:00, 900.31it/s]\n",
            "100%|██████████| 6250/6250 [00:07<00:00, 887.32it/s]\n",
            "100%|██████████| 6250/6250 [00:06<00:00, 899.00it/s]\n",
            "100%|██████████| 6250/6250 [00:06<00:00, 896.55it/s]\n",
            "100%|██████████| 6250/6250 [00:07<00:00, 880.51it/s]\n",
            "100%|██████████| 6250/6250 [00:07<00:00, 883.78it/s]\n",
            "100%|██████████| 6250/6250 [00:06<00:00, 900.99it/s]\n",
            "100%|██████████| 6250/6250 [00:07<00:00, 882.18it/s]\n",
            "100%|██████████| 6250/6250 [00:06<00:00, 902.56it/s]\n",
            "100%|██████████| 6250/6250 [00:06<00:00, 901.47it/s]\n",
            "100%|██████████| 6250/6250 [00:06<00:00, 911.83it/s]\n",
            "100%|██████████| 6250/6250 [00:06<00:00, 916.87it/s]\n",
            "100%|██████████| 6250/6250 [00:06<00:00, 900.86it/s]\n",
            "100%|██████████| 6250/6250 [00:06<00:00, 896.97it/s]\n",
            "100%|██████████| 6250/6250 [00:07<00:00, 873.40it/s]\n",
            "100%|██████████| 6250/6250 [00:07<00:00, 848.45it/s]\n",
            "100%|██████████| 6250/6250 [00:07<00:00, 879.41it/s]\n",
            "100%|██████████| 6250/6250 [00:07<00:00, 838.64it/s]\n",
            "100%|██████████| 6250/6250 [00:07<00:00, 866.62it/s]\n",
            "100%|██████████| 6250/6250 [00:07<00:00, 887.21it/s]\n",
            "100%|██████████| 6250/6250 [00:07<00:00, 866.21it/s]\n",
            "100%|██████████| 6250/6250 [00:07<00:00, 845.95it/s]\n",
            "100%|██████████| 6250/6250 [00:07<00:00, 878.07it/s]\n",
            "100%|██████████| 6250/6250 [00:07<00:00, 850.12it/s]\n",
            "100%|██████████| 6250/6250 [00:07<00:00, 877.42it/s]\n",
            "100%|██████████| 6250/6250 [00:07<00:00, 831.98it/s]\n",
            "100%|██████████| 6250/6250 [00:07<00:00, 867.99it/s]\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vOoDZL9xKcIU"
      },
      "source": [
        "The result is not as good as above. So, I think when the learning rate=0.001 and the batch-szie = 16 is good enough"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vpaY6THzIbpl",
        "outputId": "7c0f69e9-f3da-4734-b2f5-fd4a57293ec3",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "val_predictions1 = Net1.forward(x_valid)\n",
        "train_predictions1 = Net1.forward(x_train)\n",
        "\n",
        "print(\"Average train error:\")\n",
        "print(Error1.forward(train_predictions1,y_train)/len(x_train))\n",
        "\n",
        "print(\"Average validation error:\")\n",
        "print(Error1.forward(val_predictions1,y_valid)/len(x_valid))"
      ],
      "execution_count": 58,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Average train error:\n",
            "0.13734056088156757\n",
            "Average validation error:\n",
            "0.13169956061025528\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RSLoeqJTri0w"
      },
      "source": [
        "## Try different things\n",
        "How many parameters does the network have?\n",
        "\n",
        "From the above network architecture (784->64->10), we can calculate the number of parameters: 784 x 64 + 64 + 64 x 10 + 10\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Xuxcfysnrr5V"
      },
      "source": [
        "### Implement and use the cross-entropy loss instead of L2 loss."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lJisNG4KroED"
      },
      "source": [
        "class CrossEntropyCriterion(Module):\n",
        "    \"\"\"\n",
        "    This implementation of the least square loss assumes that the data comes as a 2 dimensional array\n",
        "    of size (batch_size,num_classes) and the labels as a vector of size (num_classes) \n",
        "    \"\"\"\n",
        "    def __init__(self, num_classes=10):\n",
        "        super(LeastSquareCriterion, self).__init__()\n",
        "        self.num_classes=num_classes\n",
        "    \n",
        "    def forward(self, x,labels):\n",
        "        target=np.zeros([x.shape[0],self.num_classes])\n",
        "        for i in range(x.shape[0]):\n",
        "            target[i,labels[i]]=1\n",
        "        self.output = np.sum((target-x)**2,axis=0)\n",
        "        return np.sum(self.output)\n",
        "    \n",
        "    def backward(self, x, labels):\n",
        "        self.gradInput=x\n",
        "        for i in range(x.shape[0]):\n",
        "            self.gradInput[i,labels[i]]=x[i,labels[i]]-1\n",
        "        return self.gradInput"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Q7cXEbROsDmG"
      },
      "source": [
        "### Add a parameter to vary the size of the intermediate layer."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xspYBKpPsGDi"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zZb_5Pzpr8WT"
      },
      "source": [
        "### 3 layers MLP\n",
        "Use a MLP with 3 layers and parameters for the sizes of the two intermediate layers."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nJWE3-aur_cy"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}